# -*- coding: utf-8 -*-
"""
ãƒ©ãƒãƒ³åˆ†å…‰ï¼šãƒ”ãƒ¼ã‚¯é«˜ã•æ¯”ã«ã‚ˆã‚‹æ¤œé‡ç·šä½œæˆãƒ»åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import io
import os

# ãƒšãƒ¼ã‚¸è¨­å®šï¼šæœ€åˆã«å‘¼ã³å‡ºã™
st.set_page_config(layout="wide", initial_sidebar_state='expanded')
st.sidebar.markdown("### è¨­å®š")

# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆãƒ‡ãƒãƒƒã‚°é–¢é€£ã®importã¯å‰Šé™¤ï¼‰
from common_utils import (
    detect_file_type, read_csv_file, find_index, extract_wasatch_time,
    asymmetric_least_squares, remove_outliers_and_interpolate, process_spectrum_file
)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ
plt.rcParams['font.family'] = 'DejaVu Sans'


class CalibrationAnalyzer:
    def __init__(self):
        self.spectra_data = []
        self.concentrations = []
        self.wavenumbers = None
        self.calibration_model = None  # ãƒ€ãƒŸãƒ¼ï¼ˆä»Šå›ã¯æœªä½¿ç”¨ï¼‰
        self.calibration_type = None
        self.wave_ranges = None  # [[start1, end1], [start2, end2]]
        self.fitted_params = None
        self.slope_ratio = None
        self.intercept_ratio = None

    def process_spectra_files(self, uploaded_files, start_wavenum, end_wavenum, dssn_th, savgol_wsize):
        """è¤‡æ•°ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è£œæ­£ã¨å¹³æ»‘ã‚’å®Ÿæ–½ï¼‰"""
        self.spectra_data = []
        processed_files = []

        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, uploaded_file in enumerate(uploaded_files):
            status_text.text(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
            progress_bar.progress((i + 1) / len(uploaded_files))
            try:
                wavenum, raw_spectrum, corrected_spectrum, smoothed_spectrum, file_type, file_name = process_spectrum_file(
                    uploaded_file, start_wavenum, end_wavenum, dssn_th, savgol_wsize
                )
                if wavenum is not None:
                    self.spectra_data.append({
                        'filename': file_name,
                        'wavenumbers': wavenum,
                        'raw_spectrum': raw_spectrum,
                        'corrected_spectrum': smoothed_spectrum,  # è¡¨ç¤ºç”¨ã¯å¹³æ»‘ãƒ»ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é™¤å»å¾Œ
                        'file_type': file_type,
                    })
                    processed_files.append(file_name)
                else:
                    st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {str(e)}")
                continue

        progress_bar.empty()
        status_text.empty()

        if self.spectra_data:
            self.wavenumbers = self.spectra_data[0]['wavenumbers']
            st.success(f"{len(self.spectra_data)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«å‡¦ç†ã—ã¾ã—ãŸ")
            return processed_files
        else:
            st.error("å‡¦ç†å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return []

    # ---- åŸºæœ¬ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----
    def linear_baseline_correction(self, x, y):
        """æŒ‡å®šç¯„å›²ã®å·¦å³ç«¯ç‚¹ç¾¤ã«ã‚ˆã‚‹ä¸€æ¬¡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ¨å®šã—é™¤å»"""
        n_points = min(10, max(2, len(x) // 10))
        x_base = np.concatenate([x[:n_points], x[-n_points:]])
        y_base = np.concatenate([y[:n_points], y[-n_points:]])
        coeffs = np.polyfit(x_base, y_base, 1)
        baseline = np.polyval(coeffs, x)
        return y - baseline, baseline

    def calculate_peak_height(self, y):
        return float(np.max(y))

    # ---- æ¤œé‡ç·šï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰ ----
    def create_peak_ratio_calibration(self, wave1_start, wave1_end, wave2_start, wave2_end):
        """ãƒ”ãƒ¼ã‚¯é«˜ã•æ¯” (H1/H2) ã«ã‚ˆã‚‹æ¤œé‡ç·šä½œæˆ"""
        h1_list, h2_list, ratio_list, fitting_results = [], [], [], []

        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, spectrum_data in enumerate(self.spectra_data):
            status_text.text(f"ãƒ”ãƒ¼ã‚¯è§£æä¸­: {spectrum_data['filename']} ({i+1}/{len(self.spectra_data)})")
            progress_bar.progress((i + 1) / len(self.spectra_data))

            wavenum = spectrum_data['wavenumbers']
            spectrum = spectrum_data['corrected_spectrum']

            # ç¯„å›²â‘ 
            s1 = find_index(wavenum, wave1_start)
            e1 = find_index(wavenum, wave1_end)
            x1 = wavenum[s1:e1 + 1]
            y1 = spectrum[s1:e1 + 1]
            y1_corr, b1 = self.linear_baseline_correction(x1, y1)
            h1 = self.calculate_peak_height(y1_corr)

            # ç¯„å›²â‘¡
            s2 = find_index(wavenum, wave2_start)
            e2 = find_index(wavenum, wave2_end)
            x2 = wavenum[s2:e2 + 1]
            y2 = spectrum[s2:e2 + 1]
            y2_corr, b2 = self.linear_baseline_correction(x2, y2)
            h2 = self.calculate_peak_height(y2_corr)

            h1_list.append(h1)
            h2_list.append(h2)
            ratio_list.append(h1 / h2 if h2 != 0 else np.nan)

            fitting_results.append({
                'filename': spectrum_data['filename'],
                'x1': x1, 'y1': y1, 'y1_corr': y1_corr, 'baseline1': b1, 'h1': h1,
                'x2': x2, 'y2': y2, 'y2_corr': y2_corr, 'baseline2': b2, 'h2': h2,
            })

        progress_bar.empty()
        status_text.empty()

        self.calibration_type = 'peak_ratio'
        self.wave_ranges = [[wave1_start, wave1_end], [wave2_start, wave2_end]]
        self.fitted_params = fitting_results

        return np.array(h1_list), np.array(h2_list), np.array(ratio_list), fitting_results

    def predict_concentration_ratio(self, new_spectrum_data, wave1_start, wave1_end, wave2_start, wave2_end,
                                    slope_ratio, intercept_ratio):
        """ãƒ”ãƒ¼ã‚¯æ¯”ã‹ã‚‰æ¿ƒåº¦äºˆæ¸¬"""
        wavenum = new_spectrum_data['wavenumbers']
        spectrum = new_spectrum_data['corrected_spectrum']

        # ç¯„å›²â‘ 
        s1 = find_index(wavenum, wave1_start)
        e1 = find_index(wavenum, wave1_end)
        x1 = wavenum[s1:e1 + 1]
        y1 = spectrum[s1:e1 + 1]
        y1_corr, b1 = self.linear_baseline_correction(x1, y1)
        h1 = self.calculate_peak_height(y1_corr)

        # ç¯„å›²â‘¡
        s2 = find_index(wavenum, wave2_start)
        e2 = find_index(wavenum, wave2_end)
        x2 = wavenum[s2:e2 + 1]
        y2 = spectrum[s2:e2 + 1]
        y2_corr, b2 = self.linear_baseline_correction(x2, y2)
        h2 = self.calculate_peak_height(y2_corr)

        ratio = h1 / h2 if h2 != 0 else np.nan
        if np.isnan(ratio):
            return None, h1, h2, ratio, x1, y1, y1_corr, b1, x2, y2, y2_corr, b2

        concentration = slope_ratio * ratio + intercept_ratio
        return float(concentration), h1, h2, ratio, x1, y1, y1_corr, b1, x2, y2, y2_corr, b2


# ---- UI è£œåŠ©è¡¨ç¤º ----
def display_calibration_equation(results):
    """æ¤œé‡ç·šã®æ•°å¼ã‚’è¡¨ç¤ºï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰"""
    st.subheader("æ¤œé‡ç·šæ•°å¼")
    if results['type'] == 'peak_ratio':
        m = results.get('slope_ratio')
        b = results.get('intercept_ratio')
        if m is not None and b is not None:
            eq = f"æ¿ƒåº¦ = {m:.6f} Ã— (é«˜ã•â‘ /é«˜ã•â‘¡) + {b:.6f}" if b >= 0 else \
                 f"æ¿ƒåº¦ = {m:.6f} Ã— (é«˜ã•â‘ /é«˜ã•â‘¡) - {abs(b):.6f}"
            st.markdown(f"- æ¯”ã®å¼: **{eq}**")


# ---- ã‚¿ãƒ–ï¼šæ¤œé‡ç·šä½œæˆ ----
def calibration_creation_tab(analyzer: CalibrationAnalyzer):
    st.subheader("æ¤œé‡ç·šä½œæˆï¼ˆãƒ”ãƒ¼ã‚¯é«˜ã•æ¯”ï¼‰")

    uploaded_files = st.file_uploader(
        "ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
        type=['csv', 'txt'],
        accept_multiple_files=True,
        key="calibration_uploader",
    )

    if uploaded_files:
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒ¼ã‚¿å‡¦ç†è¨­å®š
        with st.sidebar:
            st.subheader("ãƒ‡ãƒ¼ã‚¿å‡¦ç†è¨­å®š")
            start_wavenum = st.number_input("æ³¢æ•°ï¼ˆé–‹å§‹ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=400, min_value=0, max_value=4000)
            end_wavenum = st.number_input("æ³¢æ•°ï¼ˆçµ‚äº†ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=2000, min_value=start_wavenum + 1, max_value=4000)
            dssn_th = st.number_input("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=1000, min_value=1, max_value=10000) / 1e7
            savgol_wsize = st.number_input("ç§»å‹•å¹³å‡ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=5, min_value=3, max_value=101, step=2)

        processed_files = analyzer.process_spectra_files(
            uploaded_files, start_wavenum, end_wavenum, dssn_th, savgol_wsize
        )
        
        with st.expander("ğŸ”§ 29è¡Œç›®(Dåˆ—ã€œ)ã®æ™‚é–“ï¼ˆç›¸å¯¾ç§’ï¼‰ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º", expanded=False):
            for uf in uploaded_files:
                secs = extract_wasatch_time(uf)
                if secs is None:
                    st.write(f"{uf.name}: æ™‚é–“ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    st.write(f"{uf.name}: å…ˆé ­10ä»¶ -> {secs[:10]} ... (å…¨{len(secs)}ç‚¹)")
                    
        if processed_files:
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«è¡¨ç¤ºï¼ˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ç¯„å›²ï¼‰
            st.subheader("ã‚¹ãƒšã‚¯ãƒˆãƒ«ç¢ºèª")
            fig_proc = go.Figure()
            for spectrum_data in analyzer.spectra_data:
                fig_proc.add_trace(go.Scatter(
                    x=spectrum_data['wavenumbers'],
                    y=spectrum_data['corrected_spectrum'],
                    mode='lines',
                    name=spectrum_data['filename']
                ))
            fig_proc.update_layout(
                xaxis_title='Raman Shift (cmâ»Â¹)',
                yaxis_title='Intensity (a.u.)',
                height=420
            )
            fig_proc.update_xaxes(range=[start_wavenum, end_wavenum])
            st.plotly_chart(fig_proc, use_container_width=True)

            # æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
            st.subheader("æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
            key_len = f"concentration_data_{len(processed_files)}"
            if key_len not in st.session_state:
                st.session_state[key_len] = pd.DataFrame({
                    'ãƒ•ã‚¡ã‚¤ãƒ«å': processed_files,
                    'æ¿ƒåº¦': [0.0] * len(processed_files),
                    'å˜ä½': ['mg/L'] * len(processed_files),
                })

            concentration_df = st.data_editor(
                st.session_state[key_len],
                use_container_width=True,
                num_rows="fixed",
                column_config={
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": st.column_config.TextColumn(disabled=True),
                    "æ¿ƒåº¦": st.column_config.NumberColumn(
                        "æ¿ƒåº¦",
                        help="å„ã‚µãƒ³ãƒ—ãƒ«ã®æ¿ƒåº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                        min_value=0.0,
                        step=0.0001,
                        format="%.4f",
                    ),
                    "å˜ä½": st.column_config.TextColumn("å˜ä½", help="æ¿ƒåº¦ã®å˜ä½ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"),
                },
                key=f"concentration_editor_{len(processed_files)}",
            )

            # æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿ç¢ºå®š
            col_btn, col_status = st.columns([1, 2])
            with col_btn:
                concentration_confirmed = st.button("æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿ç¢ºå®š", type="secondary")
            with col_status:
                if concentration_confirmed:
                    st.session_state[key_len] = concentration_df
                    analyzer.concentrations = concentration_df['æ¿ƒåº¦'].values
                    st.success("æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®šã—ã¾ã—ãŸ")
                    st.session_state.concentration_confirmed = True
                elif st.session_state.get('concentration_confirmed', False):
                    st.info("æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿ç¢ºå®šæ¸ˆã¿")
                else:
                    st.warning("æ¿ƒåº¦ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ç¢ºå®šãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")

            # æ¤œé‡ç·šè¨­å®šï¼ˆ2 ã¤ã®è§£æç¯„å›²ï¼‰
            if st.session_state.get('concentration_confirmed', False):
                analyzer.concentrations = st.session_state[key_len]['æ¿ƒåº¦'].values

                with st.sidebar:
                    st.subheader("æ¤œé‡ç·šè¨­å®šï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰")
                    # æ³¢æ•°ç¯„å›²â‘ ï¼ˆä¿¡å·ï¼‰
                    analysis1_start = st.number_input(
                        "è§£æé–‹å§‹æ³¢æ•°â‘ :",
                        value=1695,
                        min_value=int(analyzer.wavenumbers.min()) if analyzer.wavenumbers is not None else start_wavenum,
                        max_value=int(analyzer.wavenumbers.max()) if analyzer.wavenumbers is not None else end_wavenum,
                    )
                    _a1_end_default = max(1730, analysis1_start)
                    analysis1_end = st.number_input(
                        "è§£æçµ‚äº†æ³¢æ•°â‘ :",
                        value=_a1_end_default,
                        min_value=analysis1_start,
                        max_value=int(analyzer.wavenumbers.max()) if analyzer.wavenumbers is not None else end_wavenum,
                    )
                    # æ³¢æ•°ç¯„å›²â‘¡ï¼ˆåŸºæº–ï¼‰
                    analysis2_start = st.number_input(
                        "è§£æé–‹å§‹æ³¢æ•°â‘¡:",
                        value=1605,
                        min_value=int(analyzer.wavenumbers.min()) if analyzer.wavenumbers is not None else start_wavenum,
                        max_value=int(analyzer.wavenumbers.max()) if analyzer.wavenumbers is not None else end_wavenum,
                    )
                    _a2_end_default = max(1625, analysis2_start)
                    analysis2_end = st.number_input(
                        "è§£æçµ‚äº†æ³¢æ•°â‘¡:",
                        value=_a2_end_default,
                        min_value=analysis2_start,
                        max_value=int(analyzer.wavenumbers.max()) if analyzer.wavenumbers is not None else end_wavenum,
                    )

                # å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                if analysis1_start >= analysis1_end:
                    st.error("è§£æç¯„å›²â‘ ã¯ã€é–‹å§‹ < çµ‚äº†ã€ã«ã—ã¦ãã ã•ã„ã€‚")
                    return
                if analysis2_start >= analysis2_end:
                    st.error("è§£æç¯„å›²â‘¡ã¯ã€é–‹å§‹ < çµ‚äº†ã€ã«ã—ã¦ãã ã•ã„ã€‚")
                    return

                # å¯è¦–åŒ–ï¼šè§£æç¯„å›²ï¼ˆâ‘ ã¨â‘¡ï¼‰
                st.subheader("ã‚¹ãƒšã‚¯ãƒˆãƒ«ç¢ºèªï¼ˆè§£æç¯„å›²â‘ ãƒ»â‘¡ï¼‰")
                fig2 = go.Figure()
                for spectrum_data in analyzer.spectra_data:
                    fig2.add_trace(go.Scatter(
                        x=spectrum_data['wavenumbers'],
                        y=spectrum_data['corrected_spectrum'],
                        mode='lines',
                        name=spectrum_data['filename']
                    ))
                fig2.add_vline(x=analysis1_start, line_dash="dash", line_color="red", annotation_text=f"â‘ é–‹å§‹: {analysis1_start} cmâ»Â¹")
                fig2.add_vline(x=analysis1_end,   line_dash="dash", line_color="red", annotation_text=f"â‘ çµ‚äº†: {analysis1_end} cmâ»Â¹")
                fig2.add_vline(x=analysis2_start, line_dash="dash", line_color="blue", annotation_text=f"â‘¡é–‹å§‹: {analysis2_start} cmâ»Â¹")
                fig2.add_vline(x=analysis2_end,   line_dash="dash", line_color="blue", annotation_text=f"â‘¡çµ‚äº†: {analysis2_end} cmâ»Â¹")
                fig2.update_layout(xaxis_title='Raman Shift (cmâ»Â¹)', yaxis_title='Intensity (a.u.)', height=420)
                fig2.update_xaxes(range=[start_wavenum, end_wavenum])
                st.plotly_chart(fig2, use_container_width=True)

                # æ¤œé‡ç·šä½œæˆå®Ÿè¡Œ
                if st.button("æ¤œé‡ç·šä½œæˆå®Ÿè¡Œ", type="primary"):
                    current_conc = st.session_state[key_len]['æ¿ƒåº¦'].values
                    analyzer.concentrations = current_conc
                    if len(set(analyzer.concentrations)) < 2:
                        st.error("å°‘ãªãã¨ã‚‚2ã¤ã®ç•°ãªã‚‹æ¿ƒåº¦ãŒå¿…è¦ã§ã™")
                    else:
                        with st.spinner("æ¤œé‡ç·šä½œæˆä¸­..."):
                            h1, h2, ratios, fitting_results = analyzer.create_peak_ratio_calibration(
                                analysis1_start, analysis1_end, analysis2_start, analysis2_end
                            )
                            n = min(len(h1), len(h2), len(analyzer.concentrations))
                            h1 = h1[:n]; h2 = h2[:n]; ratios = ratios[:n]
                            conc_aligned = np.array(analyzer.concentrations)[:n]

                            valid = (~np.isnan(ratios)) & (h1 > 0) & (h2 > 0)
                            v_ratio = ratios[valid]; v_conc = conc_aligned[valid]

                            if len(v_ratio) >= 2:
                                slope_ratio, intercept_ratio = np.polyfit(v_ratio, v_conc, 1)
                                y_pred = slope_ratio * v_ratio + intercept_ratio
                                ss_res = float(np.sum((v_conc - y_pred) ** 2))
                                ss_tot = float(np.sum((v_conc - np.mean(v_conc)) ** 2))
                                r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0
                                rmse = float(np.sqrt(np.mean((v_conc - y_pred) ** 2)))

                                st.session_state.calibration_results = {
                                    'type': 'peak_ratio',
                                    'heights1': h1,
                                    'heights2': h2,
                                    'ratios': ratios,
                                    'concentrations': conc_aligned,
                                    'slope_ratio': slope_ratio,
                                    'intercept_ratio': intercept_ratio,
                                    'r2': r2,
                                    'rmse': rmse,
                                    'fitting_results': fitting_results,
                                    'wave_ranges': [[analysis1_start, analysis1_end], [analysis2_start, analysis2_end]],
                                    'dssn_th': dssn_th,
                                    'savgol_wsize': savgol_wsize,
                                    'proc_range': [start_wavenum, end_wavenum],
                                    'analyzer': analyzer,
                                }
                            else:
                                st.error("æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆé«˜ã•ãŒæ­£ã§ã€ã‹ã¤â‘¡ã®é«˜ã•â‰ 0ãŒæœ€ä½2ç‚¹å¿…è¦ï¼‰ã€‚")

            # çµæœè¡¨ç¤º
            if 'calibration_results' in st.session_state:
                results = st.session_state.calibration_results
                display_calibration_equation(results)

                st.subheader("çµ±è¨ˆæŒ‡æ¨™")
                if results['type'] == 'peak_ratio':
                    st.info(
                        f"é¸æŠæ–¹æ³•: ãƒ”ãƒ¼ã‚¯æ¯”ï¼ˆâ‘ /â‘¡ï¼‰ / è§£ææ³¢æ•°ç¯„å›²â‘ : {results['wave_ranges'][0][0]}â€“{results['wave_ranges'][0][1]} cmâ»Â¹ / "
                        f"è§£ææ³¢æ•°ç¯„å›²â‘¡: {results['wave_ranges'][1][0]}â€“{results['wave_ranges'][1][1]} cmâ»Â¹ / "
                        f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: dssn_th={results['dssn_th']:.8f}, savgol_wsize={results['savgol_wsize']}"
                    )
                    c1, c2 = st.columns(2)
                    with c1:
                        st.metric("RÂ²", f"{results['r2']:.4f}")
                    with c2:
                        st.metric("RMSE", f"{results['rmse']:.4f}")

                    ratios = results['ratios']; concentrations = results['concentrations']
                    valid = (~np.isnan(ratios)) & (results['heights1'] > 0) & (results['heights2'] > 0)
                    vr, vc = ratios[valid], concentrations[valid]

                    fig_cal = go.Figure()
                    if len(vr) >= 1:
                        fig_cal.add_trace(go.Scatter(x=vr, y=vc, mode='markers', name='ãƒ‡ãƒ¼ã‚¿ (æ¯”)', marker=dict(size=8)))
                    if len(vr) >= 2:
                        xl = np.linspace(vr.min(), vr.max(), 100)
                        yl = results['slope_ratio'] * xl + results['intercept_ratio']
                        fig_cal.add_trace(go.Scatter(x=xl, y=yl, mode='lines', name='å›å¸° (æ¯”)', line=dict(dash='dash')))
                    fig_cal.update_xaxes(title_text="é«˜ã•æ¯” (â‘ /â‘¡)")
                    fig_cal.update_yaxes(title_text="æ¿ƒåº¦")
                    fig_cal.update_layout(height=420)
                    st.plotly_chart(fig_cal, use_container_width=True)

                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆä½œæˆã‚¿ãƒ–ï¼‰
                st.subheader("çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
                if results['type'] == 'peak_ratio':
                    export_df = pd.DataFrame({
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': [d['filename'] for d in analyzer.spectra_data],
                        'æ¿ƒåº¦': results['concentrations'],
                        'é«˜ã•â‘ ': results['heights1'],
                        'é«˜ã•â‘¡': results['heights2'],
                        'æ¯”(â‘ /â‘¡)': results['ratios'],
                    })
                    w1s, w1e = results['wave_ranges'][0]
                    w2s, w2e = results['wave_ranges'][1]
                    csv_buffer = io.StringIO()
                    csv_buffer.write("# æ¤œé‡ç·šè§£æçµæœï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰\n")
                    csv_buffer.write(f"# è§£ææ³¢æ•°ç¯„å›²â‘ : {w1s}-{w1e} cmâ»Â¹\n")
                    csv_buffer.write(f"# è§£ææ³¢æ•°ç¯„å›²â‘¡: {w2s}-{w2e} cmâ»Â¹\n")
                    csv_buffer.write(f"# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: dssn_th={results['dssn_th']:.8f}, savgol_wsize={results['savgol_wsize']}\n")
                    csv_buffer.write(f"# æ¯”ã®å¼: y = {results['slope_ratio']:.6f}x + {results['intercept_ratio']:.6f}\n")
                    csv_buffer.write(f"# R2={results['r2']:.4f}, RMSE={results['rmse']:.4f}\n#\n")
                    export_df.to_csv(csv_buffer, index=False)
                    st.download_button(
                        label="çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_buffer.getvalue(),
                        file_name="calibration_results_peak_ratio.csv",
                        mime="text/csv",
                    )


# ---- ã‚¿ãƒ–ï¼šã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ ----
def spectrum_analysis_tab():
    """ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æã‚¿ãƒ–ï¼ˆä½œæˆæ™‚ã®æ–¹æ³•ãƒ»æ³¢æ•°ç¯„å›²ãƒ»ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§å›ºå®šï¼‰"""
    st.subheader("ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ")

    if 'calibration_results' not in st.session_state:
        st.warning("ã¾ãšæ¤œé‡ç·šä½œæˆã‚¿ãƒ–ã§æ¤œé‡ç·šã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return

    results = st.session_state.calibration_results
    analyzer: CalibrationAnalyzer = results['analyzer']

    if results['type'] == 'peak_ratio':
        w1s, w1e = results['wave_ranges'][0]
        w2s, w2e = results['wave_ranges'][1]
        st.info(
            f"ä½¿ç”¨ä¸­ã®æ¤œé‡ç·š: ãƒ”ãƒ¼ã‚¯æ¯”ï¼ˆâ‘ /â‘¡ï¼‰ / è§£ææ³¢æ•°ç¯„å›²â‘ : {w1s}â€“{w1e} cmâ»Â¹ / è§£ææ³¢æ•°ç¯„å›²â‘¡: {w2s}â€“{w2e} cmâ»Â¹ / "
            f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: dssn_th={results['dssn_th']:.8f}, savgol_wsize={results['savgol_wsize']}"
        )

    display_calibration_equation(results)

    st.subheader("æ¿ƒåº¦ç®—å‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded_spectrum = st.file_uploader(
        "åˆ†æå¯¾è±¡ã®ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['csv', 'txt'],
        key="analysis_uploader",
    )

    if uploaded_spectrum:
        try:
            w1s, w1e = results['wave_ranges'][0]
            w2s, w2e = results['wave_ranges'][1]
            wave_start = min(w1s, w2s)
            wave_end = max(w1e, w2e)
            baseline_dssn = results.get('dssn_th', 1000/1e7)
            baseline_win  = results.get('savgol_wsize', 5)

            wavenum, raw_spectrum, corrected_spectrum, smoothed_spectrum, file_type, file_name = process_spectrum_file(
                uploaded_spectrum, wave_start, wave_end, baseline_dssn, baseline_win
            )
            if wavenum is None:
                st.error("ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return

            new_spectrum_data = {
                'filename': file_name,
                'wavenumbers': wavenum,
                'raw_spectrum': raw_spectrum,
                'corrected_spectrum': smoothed_spectrum,
            }

            st.subheader("åˆ†æã‚¹ãƒšã‚¯ãƒˆãƒ«")
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=wavenum, y=smoothed_spectrum, mode='lines', name=file_name))
            fig.add_vline(x=w1s, line_dash="dash", line_color="red",  annotation_text="â‘ é–‹å§‹")
            fig.add_vline(x=w1e, line_dash="dash", line_color="red",  annotation_text="â‘ çµ‚äº†")
            fig.add_vline(x=w2s, line_dash="dash", line_color="blue", annotation_text="â‘¡é–‹å§‹")
            fig.add_vline(x=w2e, line_dash="dash", line_color="blue", annotation_text="â‘¡çµ‚äº†")
            fig.update_layout(xaxis_title='Raman Shift (cmâ»Â¹)', yaxis_title='Intensity (a.u.)', height=420)
            st.plotly_chart(fig, use_container_width=True)

            if results['type'] == 'peak_ratio':
                m = results['slope_ratio']; b = results['intercept_ratio']
                (concentration, h1, h2, ratio,
                 x1, y1, y1_corr, b1,
                 x2, y2, y2_corr, b2) = analyzer.predict_concentration_ratio(
                    new_spectrum_data, w1s, w1e, w2s, w2e, m, b
                )

                if concentration is None or np.isnan(ratio):
                    st.error("æ¯”ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆâ‘¡ã®é«˜ã•ãŒ0ã€ã¾ãŸã¯ NaNï¼‰ã€‚è§£æç¯„å›²ã‚„åŸºæº–ãƒ”ãƒ¼ã‚¯ã®é¸å®šã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
                    return

                st.subheader("åˆ†æçµæœ")
                c1, c2, c3, c4 = st.columns(4)
                with c1: st.metric("äºˆæ¸¬æ¿ƒåº¦", f"{concentration:.4f}")
                with c2: st.metric("é«˜ã•â‘ ", f"{h1:.4f}")
                with c3: st.metric("é«˜ã•â‘¡", f"{h2:.4f}")
                with c4: st.metric("æ¯”(â‘ /â‘¡)", f"{ratio:.4f}")

                fig_fit1 = go.Figure()
                fig_fit1.add_trace(go.Scatter(x=x1, y=y1,       mode='lines', name='å…ƒãƒ‡ãƒ¼ã‚¿â‘ '))
                fig_fit1.add_trace(go.Scatter(x=x1, y=b1,       mode='lines', name='ä¸€æ¬¡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³â‘ ', line=dict(dash='dot')))
                fig_fit1.add_trace(go.Scatter(x=x1, y=y1_corr,  mode='lines', name='ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é™¤å»å¾Œâ‘ '))
                fig_fit1.update_layout(title='è§£æç¯„å›²â‘ ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°', xaxis_title='Raman Shift (cmâ»Â¹)', yaxis_title='Intensity (a.u.)', height=380)
                st.plotly_chart(fig_fit1, use_container_width=True)

                fig_fit2 = go.Figure()
                fig_fit2.add_trace(go.Scatter(x=x2, y=y2,       mode='lines', name='å…ƒãƒ‡ãƒ¼ã‚¿â‘¡'))
                fig_fit2.add_trace(go.Scatter(x=x2, y=b2,       mode='lines', name='ä¸€æ¬¡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³â‘¡', line=dict(dash='dot')))
                fig_fit2.add_trace(go.Scatter(x=x2, y=y2_corr,  mode='lines', name='ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é™¤å»å¾Œâ‘¡'))
                fig_fit2.update_layout(title='è§£æç¯„å›²â‘¡ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°', xaxis_title='Raman Shift (cmâ»Â¹)', yaxis_title='Intensity (a.u.)', height=380)
                st.plotly_chart(fig_fit2, use_container_width=True)

                st.subheader("çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
                base_name = os.path.splitext(file_name)[0]
                df_out = pd.DataFrame({
                    'ãƒ•ã‚¡ã‚¤ãƒ«å': [base_name],
                    'äºˆæ¸¬æ¿ƒåº¦': [concentration],
                    'é«˜ã•â‘ ': [h1],
                    'é«˜ã•â‘¡': [h2],
                    'æ¯”(â‘ /â‘¡)': [ratio],
                    'è§£æé–‹å§‹æ³¢æ•°â‘ ': [w1s], 'è§£æçµ‚äº†æ³¢æ•°â‘ ': [w1e],
                    'è§£æé–‹å§‹æ³¢æ•°â‘¡': [w2s], 'è§£æçµ‚äº†æ³¢æ•°â‘¡': [w2e],
                    'dssn_th': [baseline_dssn], 'savgol_wsize': [baseline_win],
                })
                csv_buffer = io.StringIO()
                csv_buffer.write("# ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æçµæœï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰\n")
                csv_buffer.write(f"# è§£ææ³¢æ•°ç¯„å›²â‘ : {w1s}-{w1e} cmâ»Â¹\n")
                csv_buffer.write(f"# è§£ææ³¢æ•°ç¯„å›²â‘¡: {w2s}-{w2e} cmâ»Â¹\n")
                csv_buffer.write(f"# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: dssn_th={baseline_dssn:.8f}, savgol_wsize={baseline_win}\n")
                csv_buffer.write(f"# æ¯”ã®å¼: y = {m:.6f}x + {b:.6f}\n#\n")
                df_out.to_csv(csv_buffer, index=False)
                st.download_button(
                    label="åˆ†æçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_buffer.getvalue(),
                    file_name=f"analysis_result_{base_name}.csv",
                    mime="text/csv",
                )

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


# ---- æ™‚ç³»åˆ—è¡¨ç¤ºã‚¿ãƒ– ----
def time_series_tab():
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚¿ãƒ–ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼=å…±é€šè¨­å®šã€ã“ã“ã§ã¯å¤‰æ›´ä¸å¯ï¼‰"""
    st.subheader("æ™‚ç³»åˆ—è¡¨ç¤º")

    if 'calibration_results' not in st.session_state:
        st.warning("ã¾ãšæ¤œé‡ç·šä½œæˆã‚¿ãƒ–ã§æ¤œé‡ç·šã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return

    results = st.session_state.calibration_results
    analyzer: CalibrationAnalyzer = results['analyzer']

    proc = results.get('proc_range', None)
    if not proc or len(proc) != 2:
        st.warning("å‡¦ç†ç¯„å›²æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã„ã£ãŸã‚“æ¤œé‡ç·šä½œæˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    proc_start, proc_end = proc
    dssn_th = results.get('dssn_th')
    savgol_wsize = results.get('savgol_wsize')
    (w1s, w1e), (w2s, w2e) = results['wave_ranges']

    st.info(
        f"è¡¨ç¤ºç¯„å›²: {proc_start}â€“{proc_end} cmâ»Â¹ / "
        f"æ¤œé‡ç·šç¯„å›²â‘ : {w1s}â€“{w1e} cmâ»Â¹, ç¯„å›²â‘¡: {w2s}â€“{w2e} cmâ»Â¹ / "
        f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: dssn_th={dssn_th:.8f}, savgol_wsize={savgol_wsize}"
    )

    uploaded_files = st.file_uploader(
        "æ™‚ç³»åˆ—ç”¨ã®ãƒ©ãƒãƒ³ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
        type=['csv', 'txt'],
        accept_multiple_files=True,
        key="timeseries_uploader",
    )

    if not uploaded_files:
        return

    def parse_timeseries(uploaded_file):
        file_name = uploaded_file.name
        ext = file_name.split('.')[-1] if '.' in file_name else ''
        data = read_csv_file(uploaded_file, ext)
        file_type = detect_file_type(data)
        uploaded_file.seek(0)

        if file_type == "wasatch":
            try:
                df = pd.read_csv(uploaded_file, encoding='shift_jis', skiprows=46)
            except Exception:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, skiprows=46)
            lambda_ex = 785
            pre_wavelength = np.array(df["Wavelength"].values)
            wavenum_full = (1e7 / lambda_ex) - (1e7 / pre_wavelength)
            processed_cols = [c for c in df.columns if str(c).startswith("Processed")]
            if len(processed_cols) == 0:
                return None
            spectra_full = df[processed_cols].to_numpy()
            labels = processed_cols
        elif file_type in ("ramaneye_old", "ramaneye_new"):
            if file_type == "ramaneye_new":
                df = pd.read_csv(uploaded_file, skiprows=9)
            else:
                df = data
            wavenum_full = np.array(df["WaveNumber"].values)
            num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            cols = [c for c in num_cols if c != "WaveNumber"]
            if len(cols) == 0:
                cols = [df.columns[-1]]
            spectra_full = df[cols].to_numpy()
            labels = [str(c) for c in cols]
        else:
            return None

        if wavenum_full[0] > wavenum_full[-1]:
            wavenum_full = wavenum_full[::-1]
            spectra_full = spectra_full[::-1, :]

        s = find_index(wavenum_full, proc_start)
        e = find_index(wavenum_full, proc_end)
        wn = np.array(wavenum_full[s:e+1])
        mat = np.array(spectra_full[s:e+1, :])  # å½¢çŠ¶: (N_wavenum, N_time)
        return file_name, wn, mat, labels

    for up in uploaded_files:
        parsed = parse_timeseries(up)
        if parsed is None:
            st.error(f"{up.name} ã‚’æ™‚ç³»åˆ—ã¨ã—ã¦è§£é‡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å¯¾å¿œå½¢å¼ï¼ˆWasatch/RamanEyeï¼‰ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
            continue
        file_name, wn, mat, time_axis = parsed
        base_name = os.path.splitext(file_name)[0]

        st.subheader(f"æ™‚ç³»åˆ—ã‚¹ãƒšã‚¯ãƒˆãƒ«: {base_name}")
        fig_hm = go.Figure(data=go.Heatmap(
            z=mat, x=time_axis, y=wn, colorbar=dict(title='Intensity')
        ))
        fig_hm.update_layout(xaxis_title='Time (s)', yaxis_title='Raman Shift (cmâ»Â¹)')
        st.plotly_chart(fig_hm, use_container_width=True)

        # ç¯„å›²â‘ /â‘¡ã®ãƒ”ãƒ¼ã‚¯é«˜ã•ã®æ™‚ç³»åˆ—
        h1_series, h2_series = [], []
        s1 = find_index(wn, w1s); e1 = find_index(wn, w1e)
        s2 = find_index(wn, w2s); e2 = find_index(wn, w2e)
        x1 = wn[s1:e1+1]; x2 = wn[s2:e2+1]
        for j in range(mat.shape[1]):
            y1 = mat[s1:e1+1, j]; y2 = mat[s2:e2+1, j]
            y1_corr, _ = analyzer.linear_baseline_correction(x1, y1)
            y2_corr, _ = analyzer.linear_baseline_correction(x2, y2)
            h1_series.append(analyzer.calculate_peak_height(y1_corr))
            h2_series.append(analyzer.calculate_peak_height(y2_corr))

        st.subheader("ç¯„å›²â‘ ãƒ»â‘¡ã®å¼·åº¦ï¼ˆæ™‚ç³»åˆ—ï¼‰")
        idx = time_axis
        fig_ts = go.Figure()
        fig_ts.add_trace(go.Scatter(x=idx, y=h1_series, mode='lines+markers', name='é«˜ã•â‘ '))
        fig_ts.add_trace(go.Scatter(x=idx, y=h2_series, mode='lines+markers', name='é«˜ã•â‘¡'))
        fig_ts.update_layout(xaxis_title='Time (s)', yaxis_title='Peak height (a.u.)', height=420)
        st.plotly_chart(fig_ts, use_container_width=True)

        df_h = pd.DataFrame({'Time_s': idx, 'é«˜ã•â‘ ': h1_series, 'é«˜ã•â‘¡': h2_series})
        csv_h = io.StringIO(); df_h.to_csv(csv_h, index=False)
        st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆâ‘ ãƒ»â‘¡ã®å¼·åº¦ï¼‰", data=csv_h.getvalue(),
                           file_name=f"{base_name}_timeseries_heights.csv", mime="text/csv")

        st.subheader("ãƒ”ãƒ¼ã‚¯æ¯” (â‘ /â‘¡) ã®æ™‚ç³»åˆ—")
        ratio_series = [(h1_series[i] / h2_series[i]) if h2_series[i] != 0 else np.nan for i in range(len(idx))]
        fig_ratio = go.Figure()
        fig_ratio.add_trace(go.Scatter(x=idx, y=ratio_series, mode='lines+markers', name='æ¯”(â‘ /â‘¡)'))
        fig_ratio.update_layout(xaxis_title='Time (s)', yaxis_title='Ratio', height=380)
        st.plotly_chart(fig_ratio, use_container_width=True)

        df_r = pd.DataFrame({'Time_s': idx, 'æ¯”(â‘ /â‘¡)': ratio_series})
        csv_r = io.StringIO(); df_r.to_csv(csv_r, index=False)
        st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ”ãƒ¼ã‚¯æ¯”ï¼‰", data=csv_r.getvalue(),
                           file_name=f"{base_name}_timeseries_ratio.csv", mime="text/csv")

        st.subheader("æ¿ƒåº¦æ›ç®—ã®æ™‚ç³»åˆ—")
        m = results.get('slope_ratio'); b = results.get('intercept_ratio')
        if m is None or b is None:
            st.warning("æ¤œé‡ç·šã®ä¿‚æ•°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ¿ƒåº¦æ›ç®—ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
        else:
            conc_series = [(m * r + b) if not np.isnan(r) else np.nan for r in ratio_series]
            fig_conc = go.Figure()
            fig_conc.add_trace(go.Scatter(x=idx, y=conc_series, mode='lines+markers', name='æ¿ƒåº¦æ›ç®—'))
            fig_conc.update_layout(xaxis_title='Time (s)', yaxis_title='Concentration (estimated)', height=380)
            st.plotly_chart(fig_conc, use_container_width=True)

            df_c = pd.DataFrame({'Time_s': idx, 'æ¿ƒåº¦(æ¨å®š)': conc_series})
            csv_c = io.StringIO(); df_c.to_csv(csv_c, index=False)
            st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¿ƒåº¦æ›ç®—ï¼‰", data=csv_c.getvalue(),
                               file_name=f"{base_name}_timeseries_concentration.csv", mime="text/csv")


# ---- ç”»é¢æ§‹æˆ ----
def calibration_mode():
    """æ¤œé‡ç·šä½œæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¿ãƒ–ç‰ˆï¼‰"""
    st.header("æ¤œé‡ç·šä½œæˆãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ”ãƒ¼ã‚¯é«˜ã•æ¯”ï¼‰")
    tab1, tab2, tab3 = st.tabs(["æ¤œé‡ç·šä½œæˆ", "ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ", "æ™‚ç³»åˆ—è¡¨ç¤º"])

    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = CalibrationAnalyzer()

    with tab1:
        calibration_creation_tab(st.session_state.analyzer)
    with tab2:
        spectrum_analysis_tab()
    with tab3:
        time_series_tab()


if __name__ == "__main__":
    calibration_mode()
